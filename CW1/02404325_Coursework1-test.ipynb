{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cb_IWF6UQRGk"
   },
   "source": [
    "# Coursework 1\n",
    "**Replace CID in the file name with your CID**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTeLZnrzE0Wy"
   },
   "source": [
    "# Outline\n",
    "\n",
    "\n",
    "- [Task 1](#task-1): Linear regression and feature selection <a name=\"index-task-1\"></a>\n",
    "  - [(1.1)](#task-11) <a name=\"index-task-11\"></a>\n",
    "  - [(1.2)](#task-12) <a name=\"index-task-12\"></a>\n",
    "  - [(1.3)](#task-13) <a name=\"index-task-13\"></a>\n",
    "  - [(1.4)](#task-14) <a name=\"index-task-14\"></a>\n",
    "- [Task 2](#task-2): Non-linear regression with Kernel Ridge Regression <a name=\"index-task-2\"></a>\n",
    "  - [(2.1)](#task-21) <a name=\"index-task-21\"></a>\n",
    "  - [(2.2)](#task-22)  <a name=\"index-task-22\"></a>\n",
    "- [Task 3](#task-3): Classification with the Multi-Layer Perceptron <a name=\"index-task-3\"></a>\n",
    "  - [(3.1)](#task-31) <a name=\"index-task-31\"></a>\n",
    "  - [(3.2)](#task-32)  <a name=\"index-task-32\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4LmL6R9N1B-"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:08.014513486Z",
     "start_time": "2026-02-09T16:36:07.968651465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(0)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_QE32lOMff_"
   },
   "source": [
    "<a name=\"task-1\"></a>\n",
    "\n",
    "# Task 1: Linear regression and feature selection [(index)](#index-task-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLl66QsJMfzc"
   },
   "source": [
    "<a name=\"task-11\"></a>\n",
    "\n",
    "## (1.1) [(index)](#index-task-11)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:08.061129869Z",
     "start_time": "2026-02-09T16:36:08.015244436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def basic_graph(x, ys, labels, *, xlog=False, ylog=False, symlog=False, xlabel=None, ylabel=None):\n",
    "    plt.figure()\n",
    "    for i, y in enumerate(ys.T):\n",
    "        plt.plot(x, y, markersize=10, label=labels[i])\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    if xlog:\n",
    "        plt.xscale(\"log\")\n",
    "    if ylog:\n",
    "        plt.yscale(\"log\")\n",
    "    if symlog:\n",
    "        plt.yscale(\"symlog\", linthresh=0.1)\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:08.107923047Z",
     "start_time": "2026-02-09T16:36:08.061934424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def r2_score(y, y_hat):\n",
    "    \"\"\"R^2 score to assess regression performance.\"\"\"\n",
    "\n",
    "    # Adjustment to avoid subtraction between (K,) and (1, K) arrays.\n",
    "    y = y.reshape(y_hat.shape)\n",
    "    y_bar = y.mean()\n",
    "\n",
    "    ss_tot = ((y - y_bar)**2).sum()\n",
    "    ss_res = ((y - y_hat)**2).sum()\n",
    "    return 1 - (ss_res/ss_tot)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:08.157506540Z",
     "start_time": "2026-02-09T16:36:08.108660619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ls(x_train, y):\n",
    "    assert x_train.shape[0] == y_train.shape[0], \"x_train and y_train must have same size\"\n",
    "    X = np.hstack([np.ones((x_train.shape[0], 1)), x_train])\n",
    "    XX = X.T @ X\n",
    "    Xy = X.T @ y\n",
    "    return np.linalg.inv(XX) @ Xy"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:08.204309606Z",
     "start_time": "2026-02-09T16:36:08.158045739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def garrote(x_train, y_train, lambd, n_iters=10000, step_size=10**(-7), c_huber=10**(-4)):\n",
    "\n",
    "    assert x_train.shape[0] == y_train.shape[0], \"x_train and y_train must have same size\"\n",
    "\n",
    "\n",
    "    n, p = x_train.shape\n",
    "\n",
    "    ls_coeffs = ls(x_train, y_train)\n",
    "    g = np.zeros(p)\n",
    "\n",
    "    beta_ls_0 = ls_coeffs[0]\n",
    "    beta_ls = ls_coeffs[1:]\n",
    "\n",
    "    # redefinitions of y_hat and X_hat so scheme can work with LASSO definition\n",
    "    y_hat = (1 / np.sqrt(n)) * (y_train - beta_ls_0)\n",
    "    X_hat = (1 / np.sqrt(n)) * (x_train @ np.diag(beta_ls))\n",
    "\n",
    "    for i in range(n_iters):\n",
    "        grad_c = grad_huber(g, c_huber)\n",
    "        grad_c[0] = 0\n",
    "\n",
    "        grad = 2 * (X_hat.T @ X_hat @ g - X_hat.T @ y_hat) + lambd * grad_c\n",
    "\n",
    "        g -= step_size * grad\n",
    "\n",
    "    return g, beta_ls"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:08.254245686Z",
     "start_time": "2026-02-09T16:36:08.207659888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def huber(beta, c=10**(-6)):\n",
    "    return np.where(np.abs(beta) <= c, (beta**2)/2, c * (np.abs(beta) - c/2))\n",
    "\n",
    "def grad_huber(beta, c=10**(-6)):\n",
    "    g = np.empty_like(beta)\n",
    "    return np.where(np.abs(beta) < c, beta, c * np.sign(beta))"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:10.595501930Z",
     "start_time": "2026-02-09T16:36:08.255038379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = pd.read_csv('asteroid_observations_test.csv')\n",
    "train_df = pd.read_csv('asteroid_observations_train.csv')\n",
    "\n",
    "lambdas = np.logspace(-1, 7.6, 15)\n",
    "\n",
    "x_train = train_df.to_numpy()[:, :7].astype(float)\n",
    "y_train = train_df.to_numpy()[:, 7].astype(float)\n",
    "x_test = test_df.to_numpy()[:, :7].astype(float)\n",
    "y_test = test_df.to_numpy()[:, 7].astype(float)\n",
    "\n",
    "beta_mat = np.zeros((15, 7))\n",
    "\n",
    "for i, lambd in enumerate(lambdas):\n",
    "    garrote_constants, betas = garrote(x_train, y_train, lambd)\n",
    "    beta_g = np.diag(betas) @ garrote_constants\n",
    "    beta_mat[i, :] = 1.0 * beta_g\n",
    "\n",
    "basic_graph(lambdas, beta_mat, labels=[rf\"$\\beta^G_{i+1}$\" for i in range(7)], xlog=True, symlog=True, xlabel=r\"$\\lambda$\", ylabel=r\"$\\beta^G_i$\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "answer here"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name=\"task-12\"></a>\n",
    "\n",
    "## (1.2) [(index)](#index-task-12)"
   ],
   "metadata": {
    "id": "AhzRRIaL9ST4"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:10.689994637Z",
     "start_time": "2026-02-09T16:36:10.642858951Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name=\"task-13\"></a>\n",
    "\n",
    "## (1.3) [(index)](#index-task-13)"
   ],
   "metadata": {
    "id": "A-b_Q8DU9YfT"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:10.735963714Z",
     "start_time": "2026-02-09T16:36:10.690731768Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name=\"task-14\"></a>\n",
    "\n",
    "## (1.4) [(index)](#index-task-14)"
   ],
   "metadata": {
    "id": "yPGM23pK9iJN"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJ1n70CNMguM"
   },
   "source": [
    "<a name=\"task-2\"></a>\n",
    "\n",
    "# Task 2: Non-linear regression with Kernel Ridge Regression [(index)](#index-task-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snlMZuPqMgxd"
   },
   "source": [
    "<a name=\"task-21\"></a>\n",
    "\n",
    "## (2.1) [(index)](#index-task-21)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:10.784192945Z",
     "start_time": "2026-02-09T16:36:10.736701647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ridge_est(x_train, y_train, lambd=0.1):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = x_train.shape\n",
    "    assert y_train.shape[0] == m, \"x_train and y_train must have same size\"\n",
    "\n",
    "    x_aug = np.hstack([np.ones((m, 1)), x_train])\n",
    "    I = np.identity(n)\n",
    "    I[0] = 0.0\n",
    "    beta = np.linalg.inv(x_aug.T @ x_aug + lambd * np.eye(n)) @ x_aug.T @ y_train\n",
    "    return beta"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name=\"task-22\"></a>\n",
    "\n",
    "## (2.2) [(index)](#index-task-22)"
   ],
   "metadata": {
    "id": "RisoEz_p97De"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:10.832678585Z",
     "start_time": "2026-02-09T16:36:10.787427304Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name=\"task-3\"></a>\n",
    "\n",
    "# Task 3: Classification with the Multi-Layer Perceptron [(index)](#index-task-3)"
   ],
   "metadata": {
    "id": "aGkpUhDW-A9o"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name=\"task-31\"></a>\n",
    "\n",
    "## (3.1) [(index)](#index-task-31)"
   ],
   "metadata": {
    "id": "glB9bSP3-WD0"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:10.881239333Z",
     "start_time": "2026-02-09T16:36:10.836118201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## EDIT THIS FUNCTION\n",
    "def dense(X, W, b):\n",
    "    \"\"\"Full-connected MLP layer.\n",
    "\n",
    "    Parameters:\n",
    "        X (np.ndarray): K x h_in array of inputs, where K is the batch size and h_in is the input dimension.\n",
    "        W (np.ndarray): h_out x h_in array for weights matrix parameters, where h_out is the output dimension.\n",
    "        b (np.ndarray): Length h_out 1-D array for bias parameters\n",
    "\n",
    "    Returns:\n",
    "        a (np.ndarray): K x h_out array of pre-activations\n",
    "    \"\"\"\n",
    "    a = np.vstack([W @ x + b for x in X]) ## <-- EDIT THIS LINE\n",
    "    return a"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:10.927928030Z",
     "start_time": "2026-02-09T16:36:10.881926533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## EDIT THIS FUNCTION\n",
    "def relu_activation(a):\n",
    "    \"\"\"ReLU activation function.\n",
    "\n",
    "    Parameters:\n",
    "        a: K x h_out array of pre-activations\n",
    "\n",
    "    Returns:\n",
    "        h: K x h_out array of post-activations\n",
    "    \"\"\"\n",
    "    # compute post-activations\n",
    "    h = np.maximum(a, 0.)  ## <-- EDIT THIS LINE\n",
    "    return h\n",
    "\n",
    "## EDIT THIS FUNCTION\n",
    "def grad_relu_activation(a):\n",
    "    \"\"\"Gradient of ReLU activation function.\n",
    "\n",
    "    Parameters:\n",
    "        a: K x h_out array of pre-activations\n",
    "\n",
    "    Returns:\n",
    "        grad: K x h_out gradient array of post-activations\n",
    "    \"\"\"\n",
    "    # compute gradient\n",
    "    grad = np.zeros_like(a)\n",
    "    grad[a > 0] = 1\n",
    "    return grad\n",
    "\n",
    "## EDIT THIS FUNCTION\n",
    "def tanh_activation(a):\n",
    "    \"\"\"Tanh activation function.\n",
    "\n",
    "    Parameters:\n",
    "        a: K x h_out array of pre-activations\n",
    "\n",
    "    Returns:\n",
    "        h: K x h_out array of post-activations\n",
    "    \"\"\"\n",
    "    # compute post-activations\n",
    "    h = 2 / (1 + np.exp(-2 * a)) - 1\n",
    "    return h\n",
    "\n",
    "## EDIT THIS FUNCTION\n",
    "def grad_tanh_activation(a):\n",
    "    \"\"\"Gradient of Tanh activation function.\n",
    "\n",
    "    Parameters:\n",
    "        a: K x h_out array of pre-activations\n",
    "\n",
    "    Returns:\n",
    "        grad: K x h_out gradient array of post-activations\n",
    "    \"\"\"\n",
    "    # compute gradient\n",
    "    grad = 1 - tanh_activation(a) ** 2\n",
    "    return grad"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:10.976928564Z",
     "start_time": "2026-02-09T16:36:10.930590100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## EDIT THIS FUNCTION\n",
    "def sigmoid_activation(a):\n",
    "    \"\"\"Sigmoid activation function. We implement here a numerically stable version\n",
    "    where sigmoid(a) = 1/(1+exp(-a)) when a => 0 and sigmoid(a) = exp(a)/(1+exp(a))\n",
    "    when a < 0.\n",
    "\n",
    "    Parameters:\n",
    "        a: K x h_out array of pre-activations\n",
    "\n",
    "    Returns:\n",
    "        h: K x h_out array of post-activations\n",
    "    \"\"\"\n",
    "\n",
    "    # handle scalar inputs\n",
    "    if np.isscalar(a):\n",
    "        a = np.array([a])\n",
    "\n",
    "    # determine indices where a is positive or negative\n",
    "    positive = a >= 0\n",
    "    negative = ~positive\n",
    "\n",
    "    # compute sigmoid for positive a\n",
    "    h = np.empty_like(a, dtype=float)\n",
    "    h[positive] = 1 / (1 + np.exp(-a[positive])) ## <-- EDIT THIS LINE\n",
    "\n",
    "    # compute sigmoid for negative a\n",
    "    exp = np.exp(a[negative])## <-- EDIT THIS LINE\n",
    "    h[negative] = exp / (1 + exp)## <-- EDIT THIS LINE\n",
    "\n",
    "    return h\n",
    "\n",
    "## EDIT THIS FUNCTION\n",
    "def grad_sigmoid_activation(a):\n",
    "    \"\"\"Gradient of Sigmoid activation function.\n",
    "\n",
    "    Parameters:\n",
    "        a: K x h_out array of pre-activations.\n",
    "\n",
    "    Returns:\n",
    "        grad: K x h_out gradient array of post-activations.\n",
    "    \"\"\"\n",
    "    # compute gradient\n",
    "    grad = sigmoid_activation(a) * (1 - sigmoid_activation(a))## <-- EDIT THIS LINE\n",
    "    return grad\n",
    "\n",
    "def softmax(a):\n",
    "    \"\"\"Softmax activation function.\n",
    "    Parameters:\n",
    "        a: K x h_out array of pre-activations.\n",
    "\n",
    "    Returns:\n",
    "        h: K x h_out array of post-activations\n",
    "    \"\"\"\n",
    "    h = np.zeros_like(a, dtype=float)\n",
    "    for k in range(a.shape[0]):\n",
    "        if np.linalg.norm(a[k] - a.max() * np.ones_like(a[k])) > 5:\n",
    "            h[k] = np.zeros_like(a[k], dtype=float)\n",
    "            index = np.argmax(a[k])\n",
    "            h[k, index] = 1.0\n",
    "        else:\n",
    "            h[k] = np.exp(a[k]) / np.sum(np.exp(a[k]))\n",
    "    return h\n",
    "\n",
    "def grad_softmax(a):\n",
    "    return softmax(a)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:11.031703576Z",
     "start_time": "2026-02-09T16:36:10.977639678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# A lookup table for activation functions by their names.\n",
    "activation_table = {\n",
    "    \"relu\": relu_activation,\n",
    "    \"sigmoid\": sigmoid_activation,\n",
    "    \"tanh\": tanh_activation,\n",
    "    # Identity function.\n",
    "    \"identity\": lambda x: x,\n",
    "    \"softmax\": softmax\n",
    "}\n",
    "\n",
    "# A lookup table for gradient of activation functions by their names.\n",
    "grad_activation_table = {\n",
    "    \"relu\": grad_relu_activation,\n",
    "    \"sigmoid\": grad_sigmoid_activation,\n",
    "    \"tanh\": grad_tanh_activation,\n",
    "    # Identity function gradient.\n",
    "    \"identity\": lambda x: np.ones_like(x),\n",
    "    \"softmax\": grad_softmax\n",
    "}\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"\n",
    "    This class represents a Multi-Layer Perceptron (MLP), that we are going\n",
    "    to use to encapsulate two components:\n",
    "        1. layers: the sequence of layers, where each layer is stored in\n",
    "            a dictionary in the format {\"W\": np.ndarray, \"b\": np.ndarray},\n",
    "            where \"W\" points to the weights array, and \"b\" points to\n",
    "            the bias vector.\n",
    "        2. rng: a pseudo random number generator (RNG) initialised to generate\n",
    "            the random weights in a reproducible manner between different\n",
    "            runtime sessions.\n",
    "    This class is also shipped with methods that perform essential operations\n",
    "    with a MLP, including:\n",
    "        - add_layers: which creates a new layer with specified dimensions.\n",
    "        - predict: applies the MLP forward pass to make predictions and produces\n",
    "            a computational graph for the forward pass that can be used to\n",
    "            compute gradients using backpropagation algorithm.\n",
    "        in addition to other light functions that return simple statistics about\n",
    "        the MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, seed=2):\n",
    "        self.layers = []\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "\n",
    "    def n_parameters(self):\n",
    "        \"\"\"Return the total number of parameters of weights and biases.\"\"\"\n",
    "        return sum(l[\"b\"].size + l[\"W\"].size for l in self.layers)\n",
    "\n",
    "    def n_layers(self):\n",
    "        \"\"\"Return current number of MLP layers.\"\"\"\n",
    "        return len(self.layers) + 1 if len(self.layers) > 0 else 0\n",
    "\n",
    "    def layer_dim(self, index):\n",
    "        \"\"\"Retrieve the dimensions of the MLP layer at `index`.\"\"\"\n",
    "        return self.layers[index][\"W\"].shape\n",
    "\n",
    "    def add_layer(self, in_dim, out_dim, activation=\"identity\"):\n",
    "        \"\"\"Add fully connected layer to MLP.\n",
    "\n",
    "        Parameters:\n",
    "            in_dim (int): The input dimension of the layer.\n",
    "            out_dim (int): The output dimension of the layer.\n",
    "            activation (str): The activation function name.\n",
    "        \"\"\"\n",
    "        # check if input-dimension matches output-dimension of previous layer\n",
    "        if self.n_layers() > 0:\n",
    "            last_out_dim, _ = self.layer_dim(-1)\n",
    "            assert in_dim == last_out_dim, f\"Input-dimension {in_dim} does not match output-dimension {last_out_dim} of previous layer.\"\n",
    "\n",
    "        # the first layer, in our convention illustrated, does not apply activation on the input features X.\n",
    "        if self.n_layers() == 0:\n",
    "            assert activation == \"identity\", \"Should not apply activations on the input features X, use Identity function for the first layer.\"\n",
    "\n",
    "\n",
    "        # store each layer as a dictionary in the list, as shown in the\n",
    "        # attached diagram.\n",
    "        self.layers.append({\n",
    "            # only for debugging.\n",
    "            \"index\": len(self.layers),\n",
    "            # apply Glorot initialisation for weights.\n",
    "            # hint: use self.rng.normal()\n",
    "            \"W\": self.rng.normal(size=(out_dim, in_dim)) * np.sqrt(2. / (in_dim + out_dim)), ## <-- EDIT THIS LINE\n",
    "            # initialise bias vector with zeros.\n",
    "            \"b\": np.zeros(out_dim), ## <-- EDIT THIS LINE\n",
    "            # store the activation function (as string)\n",
    "            \"activation\": activation\n",
    "        })\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Apply the forward pass on the input X and produce prediction and the\n",
    "        forward computation graph.\n",
    "\n",
    "        Parameters:\n",
    "            X (np.ndarray): Feature matrix.\n",
    "\n",
    "        Returns:\n",
    "            (np.ndarray, List[Dict[str, np.ndarray]]): A tuple of the\n",
    "            predictions and the computation graph as a sequence of intermediate\n",
    "            values through the MLP, specifically each layer will have a corresponding\n",
    "            intermediate values {\"a\": np.ndarray, \"h\": np.ndarray}, as shown in the\n",
    "            attached diagram above.\n",
    "        \"\"\"\n",
    "        # We assume that we work with a batch of examples (ndim==2).\n",
    "        if X.ndim == 1:\n",
    "            # If one example passed, add a dummy dimension for the batch.\n",
    "            X = X.reshape(1, -1)\n",
    "\n",
    "        # store pre- and post-activations in list\n",
    "        forward_pass = [{\"index\": 0, \"a\": X, \"h\": X}]\n",
    "\n",
    "        # iterate through hidden layers\n",
    "        for k in range(1, len(self.layers)):\n",
    "            # compute pre-activations\n",
    "            a = dense(forward_pass[k - 1][\"h\"], self.layers[k - 1][\"W\"], self.layers[k - 1][\"b\"])\n",
    "            activation = activation_table[self.layers[k][\"activation\"]]\n",
    "            forward_pass.append({\"index\": k, \"a\" : a, \"h\" : activation(a)})\n",
    "\n",
    "        y_hat = dense(forward_pass[-1][\"h\"], self.layers[-1][\"W\"], self.layers[-1][\"b\"])\n",
    "        # predicted target is output of last layer\n",
    "        return y_hat, forward_pass"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:11.081063830Z",
     "start_time": "2026-02-09T16:36:11.032631657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "    \"\"\"Compute MSE-loss\n",
    "\n",
    "    Parameters:\n",
    "        y_true: ground-truth array, with shape (K, )\n",
    "        y_pred: predictions array, with shape (K, )\n",
    "\n",
    "    Returns:\n",
    "        loss (float): MSE-loss\n",
    "    \"\"\"\n",
    "    assert y_true.size == y_pred.size, \"Ground-truth and predictions have different dimensions.\"\n",
    "\n",
    "    # Adjustment to avoid subtraction between (K,) and (1, K) arrays.\n",
    "    y_true = y_true.reshape(y_pred.shape)\n",
    "\n",
    "    # Compute MSE loss\n",
    "    loss = np.mean((y_true - y_pred) ** 2, keepdims=True)\n",
    "    return loss\n",
    "\n",
    "def grad_mse_loss(y_true, y_pred):\n",
    "    \"\"\"Compute gradient of MSE-loss\n",
    "\n",
    "    Parameters:\n",
    "        y_true: ground-truth values, shape: (K, ).\n",
    "        y_pred: prediction values, shape: (K, ).\n",
    "\n",
    "    Returns:\n",
    "        grad (np.ndarray): Gradient of MSE-loss, shape: (K, ).\n",
    "    \"\"\"\n",
    "    # Adjustment to avoid subtraction between (K,) and (1, K) arrays.\n",
    "    y_true = y_true.reshape(y_pred.shape)\n",
    "\n",
    "    # Compute gradient of MSE loss\n",
    "    grad = 2 * (y_pred - y_true) / y_true.size\n",
    "    return grad"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:11.129240554Z",
     "start_time": "2026-02-09T16:36:11.081883553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_entropy(y_true, y_pred):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "\n",
    "    return - np.sum(np.multiply(y_true, np.log(y_pred + np.ones_like(y_pred) * 1e-8)))\n",
    "\n",
    "def grad_cross_entropy(y_true, y_pred):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "\n",
    "    return y_pred - y_true"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:11.180886759Z",
     "start_time": "2026-02-09T16:36:11.129950876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def backpropagate(layers, forward_pass, delta_output):\n",
    "    \"\"\"\n",
    "    Apply the backpropagation algorithm to the MLP layers to compute the gradients starting from\n",
    "    the output layer to the input layer, and starting the chain rule from the\n",
    "    partial derivative of the loss function w.r.t the predictions\n",
    "\n",
    "    Parameters:\n",
    "        layers (List[Dict[str, np.ndarray]]): The MLP sequence of layers, as shown in the diagrams.\n",
    "        forward_pass (List[Dict[str, np.ndarray]]): The forward pass intermediate values for\n",
    "            each layer, representing a computation graph.\n",
    "        delta_output (np.ndarray): the partial derivative of the loss function w.r.t the\n",
    "            predictions, has the shape (K, 1), where K is the batch size.\n",
    "    Returns:\n",
    "        gradients (List[Dict[str, np.ndarray]]): The computed gradient using a structure symmetric in the layers, as shown\n",
    "            in the diagrams.\n",
    "\n",
    "    \"\"\"\n",
    "    #Â Create a list that will contain the gradients of all the layers.\n",
    "    gradients = []\n",
    "\n",
    "    # Initialise delta.\n",
    "    delta = delta_output\n",
    "\n",
    "    assert len(layers) == len(forward_pass), \"Number of layers is expected to match the number of forward pass layers\"\n",
    "\n",
    "    # Iterate on layers backwardly, from output to input.\n",
    "    # Calculate gradients w.r.t. weights and biases of each level and store in list of dictionaries.\n",
    "    for layer, forward_computes in reversed(list(zip(layers, forward_pass))):   # zip iterates through pairs of layers and forward_pass\n",
    "        assert forward_computes[\"index\"] == layer[\"index\"], \"Mismatch in the index.\"\n",
    "\n",
    "        h = forward_computes[\"h\"]\n",
    "        assert delta.shape[0] == h.shape[0], \"Mismatch in the batch dimension.\"\n",
    "\n",
    "        # Gradients are average gradients over batch\n",
    "        gradients.append({\"W\" : delta.T @ h / h.shape[0], ## <-- EDIT THIS LINE\n",
    "                          \"b\" : delta.mean(axis=0) })## <-- EDIT THIS LINE\n",
    "\n",
    "        # Update the delta for the next iteration\n",
    "        grad_activation_f = grad_activation_table[layer[\"activation\"]]\n",
    "        grad_activation = grad_activation_f(forward_computes[\"a\"])\n",
    "\n",
    "        # Calculate the delta for the backward layer.\n",
    "        delta = np.stack([np.diag(gi) @ layer[\"W\"].T @ di for (gi, di) in zip(grad_activation, delta)]) ## <-- EDIT THIS LINE\n",
    "\n",
    "\n",
    "    # Return now ordered list matching the layers.\n",
    "    gradients = list(reversed(gradients))\n",
    "    return gradients"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:11.229426720Z",
     "start_time": "2026-02-09T16:36:11.181376527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sgd_step(X, y, mlp, learning_rate = 1e-3):\n",
    "    \"\"\"\n",
    "    Apply a stochastic gradient descent step using the sampled batch.\n",
    "    Parameters:\n",
    "        X (np.ndarray): The input features array batch, with dimension (K, p).\n",
    "        y (np.ndarray): The ground-truth of the batch, with dimension (K, 1).\n",
    "        learning_rate (float): The learning rate multiplier for the update steps in SGD.\n",
    "    Returns:\n",
    "        updated_layers (List[Dict[str, np.ndarray]]): The updated layers after applying SGD.\n",
    "    \"\"\"\n",
    "    # Compute the forward pass.\n",
    "    y_hat, forward_pass = mlp.predict(X)## <-- EDIT THIS LINE\n",
    "\n",
    "    # y_hat_softmax = softmax(y_hat)\n",
    "\n",
    "    # Compute the partial derivative of the loss w.r.t. to predictions `y_hat`.\n",
    "    delta_output = grad_cross_entropy(y, y_hat)## <-- EDIT THIS LINE\n",
    "\n",
    "    # Apply backpropagation algorithm to compute the gradients of the MLP parameters.\n",
    "    gradients = backpropagate(mlp.layers, forward_pass, delta_output)  ## <-- SOLUTION.\n",
    "\n",
    "    # mlp.layers and gradients are symmetric, as shown in the figure.\n",
    "    updated_layers = []\n",
    "    for layer, grad in zip(mlp.layers, gradients):\n",
    "        W = layer[\"W\"] - grad[\"W\"] * learning_rate## <-- EDIT THIS LINE\n",
    "        b = layer[\"b\"] - grad[\"b\"] * learning_rate## <-- EDIT THIS LINE\n",
    "        updated_layers.append({\"W\": W, \"b\": b,\n",
    "                               # keep the activation function.\n",
    "                               \"activation\": layer[\"activation\"],\n",
    "                               # We use the index for asserts and debugging purposes only.\n",
    "                               \"index\": layer[\"index\"]})\n",
    "    return updated_layers"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:11.278761277Z",
     "start_time": "2026-02-09T16:36:11.230131141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sgd(X_train, y_train, X_test, y_test, mlp, learning_rate = 1e-3,\n",
    "        n_epochs=10, minibatchsize=1, seed=42):\n",
    "    \"\"\"\n",
    "    Run the Stochastic Gradient Descent (SGD) algorithm to optimise the parameters of MLP model to fit it on\n",
    "    the training data using MSE loss.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (np.ndarray): The training data features, with shape (N^{training}, p).\n",
    "        y_train (np.ndarray): The training data ground-truth, with shape (N^{training}, 1).\n",
    "        X_test (np.ndarray): The testing data features, with shape (N^{test}, p).\n",
    "        y_test (np.ndarray): The testing data ground-truth, with shape (N^{test}, 1).\n",
    "        mlp (MLP): The MLP object enacpsulating the MLP model.\n",
    "        learning_rate (float): The learning_rate multiplier used in updating the parameters at each iteration.\n",
    "        n_epochs (int): The number of training cycles that each covers the entire training examples.\n",
    "        minibatchsize (int): The batch size used in each SGD step.\n",
    "        seed (int): A seed for the RNG to ensure reproducibility across runtime sessions.\n",
    "\n",
    "    Returns:\n",
    "        mlp (MLP): MLP object encapuslating the trained MLP model.\n",
    "        losses_train (np.ndarray): Train losses over epochs.\n",
    "        losses_tset (np.ndarray): Test losses over epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    # get random number generator\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # compute number of iterations per epoch\n",
    "    n_iterations = int(len(y_train) / minibatchsize)\n",
    "\n",
    "    # store losses\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "\n",
    "    for i in range(n_epochs):\n",
    "\n",
    "        # shuffle data\n",
    "        p = rng.permutation(len(y_train))\n",
    "        X_train_shuffled = X_train[p]\n",
    "        y_train_shuffled = y_train[p]\n",
    "\n",
    "        for j in range(n_iterations):\n",
    "            # get batch\n",
    "            X_batch = X_train_shuffled[j*minibatchsize : (j+1)*minibatchsize]\n",
    "            y_batch = y_train_shuffled[j*minibatchsize : (j+1)*minibatchsize]\n",
    "\n",
    "            # apply sgd step\n",
    "            updated_layers = sgd_step(X_batch, y_batch, mlp, learning_rate)## <-- EDIT THIS LINE\n",
    "\n",
    "            # update weights and biases of MLP\n",
    "            mlp.layers = updated_layers## <-- EDIT THIS LINE\n",
    "\n",
    "        # compute loss at the end of each epoch\n",
    "        y_hat_train, _ = mlp.predict(X_train)\n",
    "        loss_train = mse_loss(y_train, y_hat_train).squeeze()\n",
    "        losses_train.append(loss_train)\n",
    "        y_hat_test, _ = mlp.predict(X_test)\n",
    "        loss_test = mse_loss(y_test, y_hat_test).squeeze()\n",
    "        losses_test.append(loss_test)\n",
    "\n",
    "        if (i==0) or ((i+1)%50==0):\n",
    "          print(\n",
    "              f'Epoch {i+1}/{n_epochs}: In-sample error: {loss_train}, Out-of-sample error: {loss_test},'\n",
    "              f'train R^2: {r2_score(y_train, y_hat_train):.2f}, test R^2: {r2_score(y_test, y_hat_test):.2f}.'\n",
    "               )\n",
    "\n",
    "    return mlp, losses_train, losses_test\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:11.327421918Z",
     "start_time": "2026-02-09T16:36:11.279489482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "onehot_dict = {\"MBA\" : np.array([1, 0, 0]),\n",
    "               \"TJN\" : np.array([0, 1, 0]),\n",
    "               \"OMB\" : np.array([0, 0, 1])}\n",
    "\n",
    "x_train = train_df.to_numpy()[:, :7].astype(float)\n",
    "y_train = np.array([onehot_dict[label] for label in train_df.to_numpy()[:, 8]])\n",
    "x_test = test_df.to_numpy()[:, :7].astype(float)\n",
    "y_test = np.array([onehot_dict[label] for label in test_df.to_numpy()[:, 8]])"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:11.656614080Z",
     "start_time": "2026-02-09T16:36:11.327763835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlp = MLP()\n",
    "mlp.add_layer(7, 64) # input\n",
    "mlp.add_layer(64, 64, \"relu\") # hidden 1\n",
    "mlp.add_layer(64, 32, \"relu\") # hidden 2\n",
    "mlp.add_layer(32, 3, \"relu\") # hidden 3\n",
    "\n",
    "print(\"Number of layers (including input and output layer):\",mlp.n_layers())\n",
    "print(\"Number of trainable parameters:\",mlp.n_parameters())\n",
    "\n",
    "mlp, losses_train, losses_test = sgd(x_train, y_train, x_test, y_test, mlp, learning_rate=0.04, minibatchsize=64, seed=42)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32862/1042952023.py:13: RuntimeWarning: overflow encountered in matmul\n",
      "  a = np.vstack([W @ x + b for x in X]) ## <-- EDIT THIS LINE\n",
      "/tmp/ipykernel_32862/348706230.py:35: RuntimeWarning: invalid value encountered in matmul\n",
      "  gradients.append({\"W\" : delta.T @ h / h.shape[0], ## <-- EDIT THIS LINE\n",
      "/tmp/ipykernel_32862/348706230.py:43: RuntimeWarning: invalid value encountered in matmul\n",
      "  delta = np.stack([np.diag(gi) @ layer[\"W\"].T @ di for (gi, di) in zip(grad_activation, delta)]) ## <-- EDIT THIS LINE\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:11.735959717Z",
     "start_time": "2026-02-09T16:36:11.657067741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot training progress\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(np.arange(1,11),losses_train, label=\"Train\")\n",
    "ax.plot(np.arange(1,11),losses_test, label=\"Test\")\n",
    "ax.set(title=\"Entropy vs Epochs\", xlabel = \"Epoch\", ylabel = \"CE\")\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T16:36:11.913685339Z",
     "start_time": "2026-02-09T16:36:11.736621130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label1 = y_test == \"MBA\"\n",
    "label2 = y_test == \"TJN\"\n",
    "label3 = y_test == \"OMB\"\n",
    "\n",
    "y_pred = mlp.predict(x_test)\n",
    "y_realisation = np.array()"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "array() missing required argument 'object' (pos 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[21]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      3\u001B[39m label3 = y_test == \u001B[33m\"\u001B[39m\u001B[33mOMB\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      5\u001B[39m y_pred = mlp.predict(x_test)\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m y_realisation = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: array() missing required argument 'object' (pos 0)"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name=\"task-32\"></a>\n",
    "\n",
    "## (3.2) [(index)](#index-task-32)"
   ],
   "metadata": {
    "id": "BvuMxnRl-ayJ"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
